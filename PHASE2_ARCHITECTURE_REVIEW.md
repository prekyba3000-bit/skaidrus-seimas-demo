# Phase 2 Architecture Review: Critical Analysis

**Author:** Principal Software Architect  
**Date:** January 17, 2026  
**Review Type:** Critical Technical Evaluation  
**Target Scale:** 100,000 concurrent users

---

## Executive Summary

This document provides a critical architectural review of the Phase 2 SSE implementation plan. While the overall direction is sound, **critical gaps** exist in message delivery guarantees, database query optimization, and connection management that could cause production failures at scale. This review addresses these concerns with specific, actionable recommendations.

**Overall Assessment:** ‚ö†Ô∏è **APPROVE WITH MODIFICATIONS**

**Risk Level:** üü° **MEDIUM-HIGH** - Requires architectural changes before production deployment

---

## 1. Critical Analysis: Redis Pub/Sub vs Redis Streams

### 1.1 Current Proposal: Redis Pub/Sub

**Architecture:**
```
Activity Created ‚Üí Redis Pub/Sub Channel ‚Üí All Subscribed Servers ‚Üí SSE Clients
```

### 1.2 Fundamental Flaw: Message Loss During Reconnection

**The Problem:**

Redis Pub/Sub is **fire-and-forget** with **zero message persistence**:

```typescript
// Current proposal (PROBLEMATIC)
await redisSubscriber.subscribe(`activities:user:${userId}`);
// ‚ùå If client disconnects, messages are LOST forever
// ‚ùå No acknowledgment mechanism
// ‚ùå No replay capability
```

**Failure Scenario:**
```
T=0s:   Client connects to SSE endpoint
T=5s:   Client loses network (mobile switch, WiFi drop)
T=10s:  Activity #123 created ‚Üí Published to Redis Pub/Sub
T=15s:  Client reconnects
Result: Activity #123 is LOST - user never sees it
```

**Impact at Scale:**
- **100k users** √ó **5% reconnection rate** = **5,000 lost messages/hour**
- **User experience:** Activities appear "randomly" or not at all
- **Data integrity:** No audit trail of delivery failures

---

### 1.3 Recommended Solution: Redis Streams

**Why Redis Streams:**

| Feature | Redis Pub/Sub | Redis Streams | Winner |
|---------|---------------|---------------|--------|
| **Message Persistence** | ‚ùå None | ‚úÖ Configurable retention | **Streams** |
| **Acknowledgment** | ‚ùå None | ‚úÖ Consumer groups with ACK | **Streams** |
| **Replay on Reconnect** | ‚ùå Impossible | ‚úÖ Read from last processed ID | **Streams** |
| **Backpressure Handling** | ‚ùå No | ‚úÖ Pending entries list | **Streams** |
| **Memory Efficiency** | ‚úÖ Low (no storage) | üü° Medium (retention policy) | **Pub/Sub** |
| **Latency** | ‚úÖ <1ms | ‚úÖ <2ms | **Tie** |

**Architecture with Redis Streams:**

```typescript
// Producer: Activity creation
await redis.xadd(
  "activities:stream",
  "*", // Auto-generate ID
  "type", activity.type,
  "mpId", activity.mpId,
  "data", JSON.stringify(activity)
);

// Consumer: SSE endpoint per user
const consumerGroup = `users:${userId}`;
const streamName = "activities:stream";

// Create consumer group if not exists
try {
  await redis.xgroup("CREATE", streamName, consumerGroup, "0", "MKSTREAM");
} catch (err) {
  // Group already exists
}

// Read with acknowledgment
const messages = await redis.xreadgroup(
  "GROUP", consumerGroup, userId,
  "COUNT", 10,
  "BLOCK", 5000, // Block for 5s if no messages
  "STREAMS", streamName, ">"
);

// Process messages
for (const [stream, events] of messages) {
  for (const [id, fields] of events) {
    // Send to SSE client
    res.write(`data: ${JSON.stringify(fields)}\n\n`);
    
    // Acknowledge after successful delivery
    await redis.xack(streamName, consumerGroup, id);
  }
}
```

**Benefits:**
1. **Message Persistence:** Configure retention (e.g., 24 hours)
2. **Reconnection Safety:** Client reads from last processed ID
3. **Acknowledgment:** Messages only removed after ACK
4. **Backpressure:** Pending entries list shows undelivered messages

**Configuration:**
```typescript
// Set max length to prevent unbounded growth
await redis.xadd(
  "activities:stream",
  "MAXLEN", "~", "1000000", // Keep ~1M messages
  "*",
  "data", activityData
);
```

**Recommendation:** ‚úÖ **MIGRATE TO REDIS STREAMS** before production

---

### 1.4 Hybrid Approach (Alternative)

If Redis Streams adds too much complexity initially, use **Pub/Sub with message buffer**:

```typescript
// Store recent activities in Redis List (last 1000)
await redis.lpush("activities:recent", JSON.stringify(activity));
await redis.ltrim("activities:recent", 0, 999); // Keep last 1000

// On reconnection, send recent activities
const recent = await redis.lrange("activities:recent", 0, 99);
for (const activity of recent.reverse()) {
  res.write(`data: ${activity}\n\n`);
}
```

**Trade-off:** More memory usage, but simpler than Streams. **Not recommended for 100k scale.**

---

## 2. Performance Deep-Dive: NOT EXISTS Subquery Optimization

### 2.1 Current Implementation Analysis

**Query Pattern:**
```sql
SELECT a.*, mps.*, bills.*
FROM activities a
LEFT JOIN mps ON a.mp_id = mps.id
LEFT JOIN bills ON a.bill_id = bills.id
WHERE NOT EXISTS(
  SELECT 1 FROM user_activity_reads uar
  WHERE uar.user_id = $userId 
  AND uar.activity_id = a.id
)
ORDER BY a.created_at DESC
LIMIT 20;
```

**Performance Characteristics:**
- **Index:** `(user_id, activity_id)` composite index exists ‚úÖ
- **Query Plan:** Correlated subquery executes for each row
- **Complexity:** O(N √ó M) where N = activities, M = reads per user
- **Estimated Cost:** ~500ms for 10k activities, 100 reads/user

---

### 2.2 Optimization Strategy Comparison

#### Option 1: LEFT JOIN with NULL Check (Recommended for <50k activities)

**Implementation:**
```sql
SELECT a.*, mps.*, bills.*, 
       CASE WHEN uar.activity_id IS NULL THEN false ELSE true END as is_read
FROM activities a
LEFT JOIN mps ON a.mp_id = mps.id
LEFT JOIN bills ON a.bill_id = bills.id
LEFT JOIN user_activity_reads uar 
  ON uar.activity_id = a.id AND uar.user_id = $userId
WHERE uar.activity_id IS NULL  -- Unread only
ORDER BY a.created_at DESC
LIMIT 20;
```

**Performance:**
- **Query Plan:** Single pass with hash join
- **Complexity:** O(N + M) - linear
- **Estimated Cost:** ~50ms for 10k activities
- **Index Usage:** Full index scan on `user_activity_reads(user_id, activity_id)`

**Pros:**
- ‚úÖ Simple migration (one query change)
- ‚úÖ Works with existing index
- ‚úÖ 10x performance improvement

**Cons:**
- ‚ùå Still requires full table scan on `user_activity_reads` for each user
- ‚ùå Degrades when user has >10k read items

**Recommendation:** ‚úÖ **IMPLEMENT FIRST** - Quick win, low risk

---

#### Option 2: Materialized View (Recommended for 50k-500k activities)

**Implementation:**
```sql
-- Create materialized view
CREATE MATERIALIZED VIEW user_unread_activities AS
SELECT 
  a.id as activity_id,
  a.created_at,
  u.id as user_id,
  a.mp_id,
  a.bill_id,
  a.type,
  a.metadata
FROM activities a
CROSS JOIN users u
LEFT JOIN user_activity_reads uar 
  ON uar.activity_id = a.id AND uar.user_id = u.id
WHERE uar.activity_id IS NULL
  AND a.created_at > NOW() - INTERVAL '30 days'; -- Only recent activities

-- Index for fast lookups
CREATE INDEX idx_unread_user_created 
  ON user_unread_activities(user_id, created_at DESC);

-- Refresh strategy
-- Option A: Periodic refresh (every 30s)
REFRESH MATERIALIZED VIEW CONCURRENTLY user_unread_activities;

-- Option B: Incremental refresh via trigger
CREATE OR REPLACE FUNCTION refresh_unread_view()
RETURNS TRIGGER AS $$
BEGIN
  -- Delete affected rows
  DELETE FROM user_unread_activities 
  WHERE activity_id = NEW.activity_id AND user_id = NEW.user_id;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER on_mark_read
AFTER INSERT ON user_activity_reads
FOR EACH ROW
EXECUTE FUNCTION refresh_unread_view();
```

**Query:**
```sql
SELECT a.*, mps.*, bills.*
FROM user_unread_activities uua
JOIN activities a ON a.id = uua.activity_id
LEFT JOIN mps ON a.mp_id = mps.id
LEFT JOIN bills ON a.bill_id = bills.id
WHERE uua.user_id = $userId
ORDER BY uua.created_at DESC
LIMIT 20;
```

**Performance:**
- **Query Plan:** Index scan on materialized view
- **Complexity:** O(log N) - logarithmic
- **Estimated Cost:** ~5ms for 10k activities
- **Storage:** ~500MB for 1M activities √ó 10k users (30 days)

**Pros:**
- ‚úÖ 100x performance improvement
- ‚úÖ Scales to millions of activities
- ‚úÖ Pre-computed joins

**Cons:**
- ‚ùå Storage overhead (500MB+)
- ‚ùå Refresh latency (30s stale data)
- ‚ùå Complex trigger maintenance

**Recommendation:** ‚úÖ **IMPLEMENT IF** LEFT JOIN shows p95 >100ms

---

#### Option 3: Denormalized Unread Count (Not Recommended)

**Implementation:**
```sql
-- Add column to activities table
ALTER TABLE activities ADD COLUMN unread_user_ids TEXT[];

-- Update via trigger
CREATE OR REPLACE FUNCTION update_unread_flag()
RETURNS TRIGGER AS $$
BEGIN
  IF TG_OP = 'INSERT' THEN
    -- Remove user from unread list
    UPDATE activities 
    SET unread_user_ids = array_remove(unread_user_ids, NEW.user_id::text)
    WHERE id = NEW.activity_id;
  ELSIF TG_OP = 'DELETE' THEN
    -- Add user back to unread list (if activity still exists)
    UPDATE activities 
    SET unread_user_ids = array_append(unread_user_ids, OLD.user_id::text)
    WHERE id = OLD.activity_id;
  END IF;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;
```

**Why Not Recommended:**
- ‚ùå **Array operations are slow** in PostgreSQL
- ‚ùå **Indexing limitations** - GIN indexes on arrays are memory-intensive
- ‚ùå **Write amplification** - Every mark-as-read updates activities table
- ‚ùå **Data inconsistency risk** - Array can get out of sync

**Verdict:** ‚ùå **DO NOT IMPLEMENT**

---

#### Option 4: Bloom Filter (Not Recommended for This Use Case)

**Why Not:**
- ‚ùå **False positives** - Would incorrectly mark items as read
- ‚ùå **No deletion** - Bloom filters can't remove items
- ‚ùå **Complexity** - Requires separate service (RedisBloom)
- ‚ùå **Use case mismatch** - Better for "might exist" checks, not "definitely unread"

**Verdict:** ‚ùå **DO NOT IMPLEMENT**

---

### 2.3 Recommended Optimization Path

**Phase 1 (Immediate):** LEFT JOIN optimization
- **Effort:** 2 hours
- **Risk:** Low
- **Expected Improvement:** 10x (500ms ‚Üí 50ms)

**Phase 2 (If Needed):** Materialized View
- **Trigger:** p95 latency >100ms OR >50k activities
- **Effort:** 1 week
- **Risk:** Medium (refresh strategy complexity)
- **Expected Improvement:** 100x (50ms ‚Üí 5ms)

**Monitoring:**
```typescript
// Add query timing
const start = performance.now();
const results = await db.query(...);
const duration = performance.now() - start;

if (duration > 100) {
  logger.warn({ duration, userId }, "Slow unread query - consider materialized view");
}
```

---

## 3. React Hook Interface Refinement

### 3.1 Current Proposal Issues

**Problematic Design:**
```typescript
// ‚ùå PROBLEM: Returns activities array - causes full re-render
export function useActivityStream(enabled: boolean = true) {
  const [activities, setActivities] = useState<any[]>([]);
  // Every new activity triggers re-render of entire feed
  return { activities, isConnected };
}
```

**Issues:**
1. **Full Feed Re-render:** Every new activity causes React to re-render all feed items
2. **State Management:** Activities array grows unbounded
3. **Memory Leak:** No cleanup of old activities
4. **Toast State Coupling:** Toast count logic mixed with feed state

---

### 3.2 Refined Hook Design

**File:** `client/src/hooks/useActivityStream.ts`

```typescript
import { useEffect, useRef, useCallback, useMemo } from "react";
import { trpc } from "@/lib/trpc";

interface ActivityEvent {
  type: "connected" | "new_activity" | "heartbeat" | "error";
  data: any;
  id?: string;
  timestamp: string;
}

interface UseActivityStreamOptions {
  enabled?: boolean;
  maxBufferSize?: number; // Prevent memory growth
  onNewActivity?: (activity: any) => void; // Callback for toast
  filter?: (activity: any) => boolean; // Filter activities
}

interface UseActivityStreamReturn {
  // Connection state (doesn't trigger re-renders)
  isConnected: boolean;
  connectionError: Error | null;
  
  // New activity count (separate from feed state)
  newActivityCount: number;
  clearNewActivityCount: () => void;
  
  // Stream subscription (for external consumption)
  subscribe: (callback: (activity: any) => void) => () => void;
  
  // Manual control
  reconnect: () => void;
  disconnect: () => void;
}

export function useActivityStream(
  options: UseActivityStreamOptions = {}
): UseActivityStreamReturn {
  const {
    enabled = true,
    maxBufferSize = 1000,
    onNewActivity,
    filter,
  } = options;

  // Use refs to avoid re-renders
  const isConnectedRef = useRef(false);
  const newActivityCountRef = useRef(0);
  const subscribersRef = useRef<Set<(activity: any) => void>>(new Set());
  const bufferRef = useRef<any[]>([]);

  // State only for UI updates (minimal re-renders)
  const [isConnected, setIsConnected] = useState(false);
  const [connectionError, setConnectionError] = useState<Error | null>(null);
  const [newActivityCount, setNewActivityCount] = useState(0);

  // Subscription management
  const subscribe = useCallback((callback: (activity: any) => void) => {
    subscribersRef.current.add(callback);
    return () => {
      subscribersRef.current.delete(callback);
    };
  }, []);

  // Clear new activity count
  const clearNewActivityCount = useCallback(() => {
    newActivityCountRef.current = 0;
    setNewActivityCount(0);
  }, []);

  // SSE connection
  useEffect(() => {
    if (!enabled) return;

    let subscription: { unsubscribe: () => void } | null = null;
    let reconnectTimeout: NodeJS.Timeout | null = null;
    let reconnectAttempts = 0;
    const maxReconnectAttempts = 5;

    const connect = () => {
      subscription = trpc.events.stream.subscribe(
        { lastEventId: undefined },
        {
          onData: (event: ActivityEvent) => {
            if (event.type === "connected") {
              isConnectedRef.current = true;
              setIsConnected(true);
              setConnectionError(null);
              reconnectAttempts = 0;
            } else if (event.type === "new_activity") {
              const activity = event.data;
              
              // Apply filter if provided
              if (filter && !filter(activity)) {
                return;
              }

              // Add to buffer (bounded)
              bufferRef.current.unshift(activity);
              if (bufferRef.current.length > maxBufferSize) {
                bufferRef.current.pop();
              }

              // Increment new activity count
              newActivityCountRef.current += 1;
              setNewActivityCount(prev => prev + 1);

              // Notify callback (for toast)
              onNewActivity?.(activity);

              // Notify all subscribers (without causing re-renders)
              subscribersRef.current.forEach(cb => {
                try {
                  cb(activity);
                } catch (err) {
                  console.error("Subscriber error:", err);
                }
              });
            } else if (event.type === "error") {
              setConnectionError(new Error(event.data.message));
            }
          },
          onError: (err) => {
            isConnectedRef.current = false;
            setIsConnected(false);
            setConnectionError(err);

            // Exponential backoff reconnection
            if (reconnectAttempts < maxReconnectAttempts) {
              const delay = Math.min(1000 * Math.pow(2, reconnectAttempts), 30000);
              reconnectTimeout = setTimeout(() => {
                reconnectAttempts += 1;
                connect();
              }, delay);
            }
          },
        }
      );
    };

    connect();

    return () => {
      subscription?.unsubscribe();
      if (reconnectTimeout) {
        clearTimeout(reconnectTimeout);
      }
    };
  }, [enabled, filter, maxBufferSize, onNewActivity]);

  // Manual controls
  const reconnect = useCallback(() => {
    // Force reconnection by unmounting/remounting effect
    // (Implementation depends on tRPC subscription API)
  }, []);

  const disconnect = useCallback(() => {
    subscription?.unsubscribe();
  }, []);

  return {
    isConnected,
    connectionError,
    newActivityCount,
    clearNewActivityCount,
    subscribe,
    reconnect,
    disconnect,
  };
}
```

**Usage in ActivityFeed:**

```typescript
export function ActivityFeed({ ... }) {
  const [hideRead, setHideRead] = useState(false);
  
  // Toast callback (doesn't trigger feed re-render)
  const handleNewActivity = useCallback((activity: any) => {
    // Toast logic here - separate from feed state
  }, []);

  // Stream hook (minimal re-renders)
  const {
    isConnected,
    newActivityCount,
    clearNewActivityCount,
    subscribe,
  } = useActivityStream({
    enabled: true,
    onNewActivity: handleNewActivity,
    filter: (activity) => {
      // Filter by followed MPs, etc.
      return true;
    },
  });

  // Subscribe to stream for feed updates (optimistic)
  useEffect(() => {
    const unsubscribe = subscribe((activity) => {
      // Update feed optimistically via React Query
      queryClient.setQueryData(
        ["activities", "getFeed"],
        (old: any) => {
          // Prepend new activity
          return {
            ...old,
            pages: [
              {
                items: [{ activity, mp: activity.mp, bill: activity.bill }],
                nextCursor: old?.pages[0]?.nextCursor,
              },
              ...(old?.pages || []),
            ],
          };
        }
      );
    });
    return unsubscribe;
  }, [subscribe, queryClient]);

  // Paginated feed (initial load)
  const { data: feedData } = trpc.activities.getFeed.useInfiniteQuery(
    { limit, excludeRead: hideRead },
    {
      getNextPageParam: lastPage => lastPage.nextCursor,
      refetchInterval: false, // No polling
    }
  );

  return (
    <div>
      <NewActivityToast
        count={newActivityCount}
        onDismiss={clearNewActivityCount}
        onView={() => {
          feedRef.current?.scrollIntoView({ behavior: "smooth" });
          clearNewActivityCount();
        }}
      />
      {/* Feed items */}
    </div>
  );
}
```

**Key Improvements:**
1. ‚úÖ **Minimal Re-renders:** Uses refs for internal state
2. ‚úÖ **Bounded Memory:** `maxBufferSize` prevents unbounded growth
3. ‚úÖ **Separation of Concerns:** Toast state separate from feed state
4. ‚úÖ **Subscription Pattern:** External components can subscribe without coupling
5. ‚úÖ **Error Handling:** Exponential backoff reconnection

---

## 4. Backpressure and Connection Limiting

### 4.1 Current Plan Gap

**Missing from Roadmap:**
- ‚ùå No backpressure handling strategy
- ‚ùå No connection limiting per user/IP
- ‚ùå No rate limiting on SSE endpoint
- ‚ùå No memory limits for SSE connections

---

### 4.2 Backpressure Strategy

**Problem:** Client receives messages faster than it can process them.

**Solution: Flow Control with Backpressure Signals**

```typescript
// Server-side: Check client buffer before sending
app.get("/api/events/activities", async (req, res) => {
  // Set low water mark (pause sending when buffer > 10KB)
  const LOW_WATER_MARK = 10 * 1024; // 10KB
  const HIGH_WATER_MARK = 50 * 1024; // 50KB

  let bufferSize = 0;
  let isPaused = false;

  const sendMessage = (data: string) => {
    if (isPaused) {
      // Queue message instead of sending
      messageQueue.push(data);
      return;
    }

    const message = `data: ${data}\n\n`;
    bufferSize += Buffer.byteLength(message, "utf8");

    // Check backpressure
    if (!res.write(message)) {
      // Buffer full - pause sending
      isPaused = true;
      res.once("drain", () => {
        isPaused = false;
        // Flush queued messages
        while (messageQueue.length > 0 && !isPaused) {
          const queued = messageQueue.shift();
          if (queued) {
            sendMessage(queued);
          }
        }
      });
    }

    // Reset buffer size periodically
    if (bufferSize > HIGH_WATER_MARK) {
      bufferSize = 0; // Reset counter
    }
  };

  // Subscribe to Redis Streams
  const subscriber = redisPubSub.createSubscriber();
  await subscriber.xreadgroup(...);

  subscriber.on("message", (channel, message) => {
    sendMessage(message);
  });
});
```

**Client-side: Backpressure Detection**

```typescript
// React hook: Detect slow processing
const useActivityStream = () => {
  const processingQueueRef = useRef<any[]>([]);
  const isProcessingRef = useRef(false);

  const processActivity = useCallback(async (activity: any) => {
    processingQueueRef.current.push(activity);

    if (isProcessingRef.current) {
      return; // Already processing
    }

    isProcessingRef.current = true;

    while (processingQueueRef.current.length > 0) {
      const next = processingQueueRef.current.shift();
      
      // Process with timeout
      await Promise.race([
        handleActivity(next),
        new Promise((_, reject) => 
          setTimeout(() => reject(new Error("Timeout")), 5000)
        ),
      ]);

      // Check queue size - if >100, pause SSE
      if (processingQueueRef.current.length > 100) {
        // Send backpressure signal to server
        await fetch("/api/events/activities/pause", { method: "POST" });
      }
    }

    isProcessingRef.current = false;
  }, []);

  return { processActivity };
};
```

---

### 4.3 Connection Limiting

**Per-User Connection Limit:**

```typescript
// Connection manager
class ConnectionManager {
  private connections = new Map<string, Set<Response>>();
  private readonly MAX_CONNECTIONS_PER_USER = 3;

  addConnection(userId: string, res: Response): boolean {
    const userConnections = this.connections.get(userId) || new Set();
    
    if (userConnections.size >= this.MAX_CONNECTIONS_PER_USER) {
      return false; // Reject connection
    }

    userConnections.add(res);
    this.connections.set(userId, userConnections);

    // Cleanup on disconnect
    res.on("close", () => {
      userConnections.delete(res);
      if (userConnections.size === 0) {
        this.connections.delete(userId);
      }
    });

    return true;
  }

  getConnectionCount(userId: string): number {
    return this.connections.get(userId)?.size || 0;
  }
}

const connectionManager = new ConnectionManager();

// In SSE endpoint
app.get("/api/events/activities", async (req, res) => {
  const ctx = await createContext({ req, res });
  if (!ctx.user) {
    return res.status(401).json({ error: "Unauthorized" });
  }

  // Check connection limit
  if (!connectionManager.addConnection(ctx.user.openId, res)) {
    return res.status(429).json({ 
      error: "Too many connections",
      message: "Maximum 3 concurrent connections allowed",
    });
  }

  // ... SSE logic ...
});
```

**Per-IP Rate Limiting:**

```typescript
import rateLimit from "express-rate-limit";

const sseRateLimiter = rateLimit({
  windowMs: 60 * 1000, // 1 minute
  max: 5, // 5 connections per minute per IP
  message: {
    error: "Too many connection attempts",
    message: "Please wait before reconnecting",
  },
  standardHeaders: true,
  legacyHeaders: false,
  skip: (req) => {
    // Skip for authenticated users (they have per-user limits)
    return !!req.user;
  },
});

app.get("/api/events/activities", sseRateLimiter, async (req, res) => {
  // ... SSE logic ...
});
```

**Global Connection Limit:**

```typescript
const MAX_TOTAL_CONNECTIONS = 10000; // Per server
let totalConnections = 0;

app.get("/api/events/activities", async (req, res) => {
  if (totalConnections >= MAX_TOTAL_CONNECTIONS) {
    return res.status(503).json({
      error: "Service unavailable",
      message: "Maximum connections reached. Please try again later.",
    });
  }

  totalConnections += 1;
  res.on("close", () => {
    totalConnections -= 1;
  });

  // ... SSE logic ...
});
```

---

### 4.4 Memory Management

**Connection Memory Limits:**

```typescript
// Monitor memory usage per connection
const connectionMemory = new Map<string, number>();
const MAX_MEMORY_PER_CONNECTION = 1 * 1024 * 1024; // 1MB

app.get("/api/events/activities", async (req, res) => {
  const connectionId = randomUUID();
  let memoryUsed = 0;

  const sendMessage = (data: string) => {
    const messageSize = Buffer.byteLength(data, "utf8");
    
    if (memoryUsed + messageSize > MAX_MEMORY_PER_CONNECTION) {
      // Close connection if memory limit exceeded
      logger.warn({ connectionId, memoryUsed }, "Connection memory limit exceeded");
      res.end();
      return;
    }

    memoryUsed += messageSize;
    connectionMemory.set(connectionId, memoryUsed);
    res.write(`data: ${data}\n\n`);
  };

  res.on("close", () => {
    connectionMemory.delete(connectionId);
  });
});
```

---

## 5. 6-Week Roadmap Validation

### 5.1 Current Roadmap Assessment

| Phase | Duration | Complexity | Risk | Assessment |
|-------|----------|------------|------|------------|
| **2.1: Foundation** | 2 weeks | Medium | Low | ‚ö†Ô∏è **UNDERESTIMATED** |
| **2.2: Optimizations** | 2 weeks | High | Medium | ‚ö†Ô∏è **UNDERESTIMATED** |
| **2.3: Scaling** | 2 weeks | High | High | ‚úÖ **REALISTIC** |

---

### 5.2 Revised Roadmap with Critical Additions

#### **Phase 2.1: Foundation (3 weeks, not 2)**

**Week 1:**
- [ ] Day 1-2: Redis Streams setup (not Pub/Sub)
- [ ] Day 3-4: SSE endpoint with connection management
- [ ] Day 5: Connection limiting & rate limiting
- [ ] Day 6-7: Testing & bug fixes

**Week 2:**
- [ ] Day 1-3: Frontend SSE hook (refined design)
- [ ] Day 4-5: Integration into ActivityFeed
- [ ] Day 6-7: Backpressure handling

**Week 3:**
- [ ] Day 1-3: Message persistence & replay on reconnect
- [ ] Day 4-5: Error handling & reconnection logic
- [ ] Day 6-7: Load testing (100 concurrent users)

**Deliverable:** Production-ready SSE foundation with message guarantees

---

#### **Phase 2.2: Optimizations (3 weeks, not 2)**

**Week 4:**
- [ ] Day 1-2: LEFT JOIN query optimization
- [ ] Day 3-4: Performance testing & monitoring
- [ ] Day 5-7: Cache invalidation fixes

**Week 5:**
- [ ] Day 1-3: Optimistic UI updates
- [ ] Day 4-5: "New Activity" toast implementation
- [ ] Day 6-7: User testing & feedback

**Week 6:**
- [ ] Day 1-3: Materialized view (if needed based on metrics)
- [ ] Day 4-5: Query performance tuning
- [ ] Day 6-7: Documentation

**Deliverable:** Optimized queries + polished UX

---

#### **Phase 2.3: Scaling (2 weeks - unchanged)**

**Week 7:**
- [ ] Day 1-3: Load testing (1000+ concurrent users)
- [ ] Day 4-5: Redis Streams consumer group optimization
- [ ] Day 6-7: Memory profiling & optimization

**Week 8:**
- [ ] Day 1-3: Monitoring & alerting setup
- [ ] Day 4-5: Documentation & runbooks
- [ ] Day 6-7: Production deployment

**Deliverable:** Scalable system supporting 100k+ users

---

### 5.3 Critical Dependencies

**Must Complete Before Phase 2.1:**
1. ‚úÖ Redis Streams infrastructure setup
2. ‚úÖ Connection manager implementation
3. ‚úÖ Rate limiting configuration
4. ‚úÖ Monitoring dashboard (connection counts, message rates)

**Must Complete Before Phase 2.2:**
1. ‚úÖ Query performance baseline metrics
2. ‚úÖ Materialized view decision (based on p95 latency)
3. ‚úÖ Cache invalidation strategy finalized

---

## 6. Final Recommendations

### 6.1 Immediate Actions (Before Implementation)

1. **‚úÖ MIGRATE TO REDIS STREAMS** - Critical for message delivery guarantees
2. **‚úÖ IMPLEMENT CONNECTION LIMITING** - Prevent resource exhaustion
3. **‚úÖ ADD BACKPRESSURE HANDLING** - Prevent memory leaks
4. **‚úÖ EXTEND TIMELINE TO 8 WEEKS** - Account for complexity

### 6.2 Architecture Decisions

| Decision | Current Plan | Recommended | Priority |
|----------|--------------|-------------|----------|
| **Message Broker** | Redis Pub/Sub | **Redis Streams** | üî¥ **CRITICAL** |
| **Query Optimization** | Not specified | **LEFT JOIN first, Materialized View if needed** | üü° **HIGH** |
| **Connection Management** | Not specified | **Per-user limits + global limits** | üî¥ **CRITICAL** |
| **Backpressure** | Not specified | **Flow control with watermarks** | üü° **HIGH** |
| **Hook Design** | Basic array state | **Ref-based with subscriptions** | üü¢ **MEDIUM** |

### 6.3 Risk Mitigation

**High-Risk Items:**
1. **Message Loss:** Mitigated by Redis Streams + acknowledgment
2. **Connection Exhaustion:** Mitigated by connection limiting
3. **Memory Leaks:** Mitigated by backpressure + bounded buffers
4. **Query Performance:** Mitigated by LEFT JOIN optimization

**Monitoring Requirements:**
- Connection count per server
- Message delivery latency (p50, p95, p99)
- Query execution time (p95 target: <100ms)
- Redis Streams memory usage
- SSE connection error rate

---

## 7. Conclusion

**Overall Assessment:** The Phase 2 plan is **architecturally sound** but requires **critical modifications** before production:

1. ‚úÖ **Redis Streams** instead of Pub/Sub (message persistence)
2. ‚úÖ **Connection limiting** and backpressure handling
3. ‚úÖ **LEFT JOIN optimization** for database queries
4. ‚úÖ **Refined React hook** design for minimal re-renders
5. ‚úÖ **Extended timeline** (8 weeks instead of 6)

**Confidence Level:** üü¢ **HIGH** - With these modifications, the system will scale to 100k users reliably.

**Next Steps:**
1. Review and approve modified architecture
2. Set up Redis Streams infrastructure
3. Begin Phase 2.1 implementation with revised timeline

---

**Document Version:** 1.0  
**Review Status:** ‚úÖ **APPROVED WITH MODIFICATIONS**  
**Risk Level:** üü° **MEDIUM** (reduced from HIGH after modifications)
